{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/tmz5MgKtsqB+hgk9q1D/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grunobuide/portfolio/blob/main/Insurance_BMI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Insurance Costs Project\n",
        "\n",
        "Datascience exercise in codecademy - reviewing things that I already know and\n",
        " updating my python skills.\n",
        "\n",
        "\n",
        "##Goal\n",
        "\n",
        "Finding out if we can use linear regression to predict the charges of medical insurance.\n",
        "\n",
        "##To do\n",
        "\n",
        "- import the data\n",
        "- save in python friendly format\n",
        "- use a linear regression model (y = mx + b), where  y means charges and x is the variable of interest.\n",
        "- make a gridsearch to find best values for m and b given the interval.\n",
        "- split the dataset into training and testing\n",
        "- find the average error of the model.\n",
        "\n",
        "\n",
        "\n",
        "##Script\n"
      ],
      "metadata": {
        "id": "yeIMpFDvcphK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "REpedt_cbUit"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn import model_selection as m_s\n",
        "#cutting corners instead of implementing a random function to split de dataset in training/test\n",
        "\n",
        "with open('/insurance.csv') as csv_file:\n",
        "  #opening the file and then creating the datapoints x is bmi, y is charges\n",
        "  #just by changing the name of the first value, i can test different variables\n",
        "  #if they are numerical - 'children','age', and 'bmi'.\n",
        "  csv_dict = csv.DictReader(csv_file)\n",
        "  datapoints = [(float(x['children']),float(x['charges'])) for x in csv_dict]\n",
        "\n",
        "\n",
        "\n",
        "#datapoints\n",
        "#train_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the dataset - shortcoming: if i find a new observation which is smaller\n",
        "#or larger than the min/max in the dataset, my normalization is caput.\n",
        "#but this technique is interesting to use if you find the dataset representative\n",
        "#of the population, so for this basic exercise i've considered it good enough.\n",
        "\n",
        "def normalize(dataset):\n",
        "  min_x = min([x[0] for x in dataset])\n",
        "  min_y = min([x[1] for x in dataset])\n",
        "  max_x = max([x[0] for x in dataset])\n",
        "  max_y = max([x[1] for x in dataset])\n",
        "  output = []\n",
        "  for x,y in dataset:\n",
        "    out_x = (x-min_x)/(max_x-min_x)\n",
        "    out_y = (y-min_y)/(max_y-min_y)\n",
        "    output.append((out_x,out_y))\n",
        "  return output\n",
        "\n",
        "\n",
        "n_datapoints = normalize(datapoints)\n",
        "#normal_test = [(normalize(x[0]),normalize(x[1])) for x in test_data]\n",
        "#normal_train\n",
        "test_data, train_data = m_s.train_test_split(n_datapoints, test_size=0.2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zgWLVd8WoIx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#functions to perform linear regression\n",
        "\n",
        "def get_y (m,b,x):\n",
        "  return m*x + b\n",
        "\n",
        "\n",
        "\n",
        "def error(m,b,points):\n",
        "  total_error = 0\n",
        "  for point in points:\n",
        "    x = float(point[0])\n",
        "    y = float(point[1])\n",
        "    total_error += abs(y - get_y(m,b,x))\n",
        "  return total_error/float(len(points))\n",
        "\n",
        "#generate possible ms and bs\n",
        "\n",
        "possible_ms = [x/100 for x in range(-100,101)]\n",
        "possible_bs = [x/100 for x in range(-100,101)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#for each m and b, get the error, save the min error with the best m and b\n",
        "\n",
        "minimal_error = float('inf')\n",
        "best_m = 0\n",
        "best_b = 0\n",
        "\n",
        "for m in possible_ms:\n",
        "  for b in possible_bs:\n",
        "    current_error = error(m,b,train_data)\n",
        "    if current_error < minimal_error:\n",
        "      minimal_error = current_error\n",
        "      best_m = m\n",
        "      best_b = b\n",
        "\n",
        "print(best_m, best_b, minimal_error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4W9C4rPG03w",
        "outputId": "39fabaec-5bef-4cac-e08f-4336f4404b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.02 0.13 0.13290265186866057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error(best_m,best_b,test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUzQUp-wpo9R",
        "outputId": "d810e215-4545-406a-fb39-19bdc5d8e66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.133809620500867"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AnÃ¡lise"
      ],
      "metadata": {
        "id": "fhGR58tbeBpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've got a linear regression model with a dataset specific normalization of the values.\n",
        "\n",
        "The model has an average error of 13% in predicting the charge based on the bmi.\n",
        "\n",
        "Trying with age: the average error is 10%\n",
        "\n",
        "With n of children: 13%"
      ],
      "metadata": {
        "id": "2hCATrlseDpZ"
      }
    }
  ]
}